# 基本概念

## 超参数（Hyperparameters

是用于控制模型训练过程的参数，其值在训练之前设定，而不是通过训练数据学习得到。与模型参数不同，超参数通常不能通过训练数据直接估计或学习，而是需要手动设置或通过试验搜索来确定

* 学习率（Learning Rate）： 控制模型参数在每次迭代中更新的步长大小。较大的学习率可能导致模型不稳定或无法收敛，而较小的学习率可能导致训练速度过慢。
* 正则化参数（Regularization Parameter）： 控制模型的复杂度，有助于防止过拟合。正则化参数通常包括 L1 正则化和 L2 正则化的权重。
* 隐藏层单元数（Number of Hidden Units）： 控制神经网络隐藏层中的单元数量，影响模型的容量和复杂度。
* 批量大小（Batch Size）： 每次迭代中用于训练的样本数量。较大的批量大小可以加速训练过程，但可能导致内存消耗增加。
* 迭代次数（Number of Iterations）或 Epochs： 控制模型在训练数据上迭代的次数。
* 优化算法（Optimization Algorithm）： 控制模型参数更新的算法，常见的优化算法包括随机梯度下降（SGD）、Adam、RMSProp 等。
* 激活函数（Activation Function）： 控制神经网络中每个神经元的输出，常见的激活函数包括 Sigmoid、Tanh、ReLU 等。
* Dropout: Keras 中的 Dropout 层是一种正则化技术，用于减少神经网络的过拟合问题。Dropout 层在训练过程中随机将输入单元的一部分设置为零，以一定的概率丢弃这些单元，从而防止网络对特定输入数据的过度依赖，增加模型的泛化能力。

